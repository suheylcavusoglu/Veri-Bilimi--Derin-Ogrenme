{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVRİŞİMLİ SİNİR AĞLARI (CNN) İLE KATI ATIK TESPİTİ\n",
    "\n",
    "1) İş Problemi (Business Problem)\n",
    "\n",
    "2) Veriyi Anlamak (Data Understanding)\n",
    "\n",
    "3) Veriyi Hazırlamak (Data Preparation)\n",
    "\n",
    "4) Modelleme (Modeling)\n",
    "\n",
    "5) Değerlendirme (Evaluation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) İş Problemi (Business Problem)\n",
    "\n",
    "İş Problemi Nedir?\n",
    "\n",
    "Katı atıkların, cam - kağıt - karton - plastik - metal - çöp kategorilerine otonom bir şekilde ayrılması gerekmektedir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Veriyi Anlamak (Data Understanding)\n",
    "\n",
    "Veri Seti Hikayesi\n",
    "\n",
    "Bu proje kapsamında kullanacağımız veri seti TrashNet isimli veri setidir. Stanford Üniversitesi öğrencileri tarafından hazırlanmıştır.\n",
    "Veri seti altı farklı sınıftan oluşmaktadır. Veri setinde Cam, Kağıt, Karton, Plastik, Metal ve Çöp olmak üzere toplamda 2527 adet görüntü bulunmaktadır.\n",
    "\n",
    "Görüntülerin dağılımı:\n",
    "- 501 cam\n",
    "- 594 kağıt\n",
    "- 403 karton\n",
    "- 482 plastik\n",
    "- 410 metal\n",
    "- 137 çöp\n",
    "\n",
    "Görüntüler beyaz bir panoya yerleştirilerek ve güneş ışığı veya oda aydınlatması kullanılarak çekilmiştir. Görüntüler, 512x384 piksel boyutlarında ve 3 (RGB) kanallıdır."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Gerekli Kütüphanelerin Import İşlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25859 sha256=4daa70721a76e65d0a51432f2e4763ac38bd5d78705c88d607548ecb8f30903d\n",
      "  Stored in directory: c:\\users\\suheyl\\appdata\\local\\pip\\cache\\wheels\\f4\\4b\\8b\\a9c23da464a09c6ad0a131c1752079bc85f9f1677c7b78e87d\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.68-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "     ---------------------------------------- 38.2/38.2 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\suheyl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (1.21.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi okuma ve işleme adımında kullanılacak olan kütüphaneler\n",
    "\n",
    "import cv2\n",
    "import urllib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random, os, glob\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Warningleri kapatmak için kullanılmaktadır.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Model değerlendirme için kullanılacak olan kütüphaneler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, SpatialDropout2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Veri Setinin Okunması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"D:\\\\Süheyl\\\\Python_Docs\\\\Courses\\\\Turkcell_Geleceği_Yazanlar\\\\Data_Science_Course\\\\Python_for_DataScience-master\\\\Derin Öğrenme\\\\CNN\\\\_archive\\\\Garbage classification\\\\Garbage classification\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target size ve Label Değerlerinin Belirlenmesi\n",
    "\n",
    "target_size = (224, 224)\n",
    "\n",
    "waste_labels = {\"cardboard\": 0, \n",
    "                \"glass\": 1, \n",
    "                \"metal\" : 2, \n",
    "                \"paper\" : 3, \n",
    "                \"plastic\" : 4, \n",
    "                \"trash\" : 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(path):\n",
    "    \"\"\"\n",
    "Görsellerin bulunduğu dizindeki görüntüyü okuyup etiketlerini oluşturur.\n",
    "Parametreler:\n",
    "path: Görsellerin bulunduğu dizini ifade eder.\n",
    "Return:\n",
    "x: Görüntülere ait matris bilgilerini tutar.\n",
    "labels: Görüntünün ait olduğu sınıf bilgisini tutan liste.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    x = []\n",
    "    labels = []\n",
    "\n",
    "    # Gönderdiğimiz pathdeki görüntüleri listeleyip sıralamaktadır.\n",
    "    image_paths = sorted(list(paths.list_images(path)))\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Belirtilen pathdeki görüntüler openCV kütüphanesi ile okunmaktadır.\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Okunan görüntüler başlangıçta belirlenen target_size'a göre yeniden ölçeklendirilir.\n",
    "        img = cv2.resize(img, target_size)\n",
    "        \n",
    "        # Ölçeklendirilen görüntüler x listesine eklenir.\n",
    "        x.append(img)\n",
    "        \n",
    "        # Her bir path \"/\" ifadesi ile ayrıldığında dönen listenin sonran ikinci elamanı label'ı temsil etmektedir.\n",
    "        label = image_path.split(os.path.sep)[-2]\n",
    "        \n",
    "        # Yakalanan labelların sayısal değer karşılıklarının olduğu waste_labels sözlüğü içerisinden gönderilen key\n",
    "        # değerine karşılık value değeri alınarak label oluşturulur.\n",
    "        labels.append(waste_labels[label])\n",
    "\n",
    "    # Veri seti random bir şekilde karıştırılır.\n",
    "    x, labels = shuffle(x, labels, random_state=42)\n",
    "\n",
    "    # Boyut ve Sınıf bilgisi raporlanmaktadır.\n",
    "    print(f\"X boyutu: {np.array(x).shape}\")\n",
    "    print(f\"Label sınıf sayısı: {len(np.unique(labels))} Gözlem sayısı: {len(labels)}\")\n",
    "\n",
    "    return x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, labes = load_datasets(dir_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdfc03b9e8b1be78256861c432074ab725f06a38536a47f76a84eb781a3309dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
